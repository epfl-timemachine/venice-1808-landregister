{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "store_file = 'allsommarioni_owners standardised forms_dataset_V2.xlsx'\n",
    "# in the same file there are corrections & new additions to the transcription\n",
    "SPLIT_IDX = 154\n",
    "new_transc = pd.read_excel(store_file, sheet_name='LETTERE ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two lines in the middle that isabella put in blank to make a separation needs to be removed before integrating the new transcription\n",
    "new_transc = pd.concat([new_transc.iloc[:SPLIT_IDX], new_transc.iloc[SPLIT_IDX+2:]]).rename(columns={'area': 'page'})\n",
    "\n",
    "replace_d = {'numero_della_mappa': 'parcel_number',\n",
    "             'subalterno': 'sub_parcel_number',\n",
    "              'corr_as': 'austrian_cadaster_correspondance',\n",
    "              'corr_ai': 'austro_italian_cadaster_correspondance',\n",
    "              'denom_pezzi_di_terra':'house_number',\n",
    "              'possessore': 'owner',\n",
    "              'possessore_standardised': 'owner_standardised',\n",
    "              'qualitÃ ': 'quality',\n",
    "              'uniqueID': 'unique_id',\n",
    "              'standardised_fonction': 'qualities',\n",
    "              'place_acronym': 'district_acronym'\n",
    "}\n",
    "img_to_double_letter_pn = {\n",
    "    \"reg6bis/0177\": [\"RA\", \"RB\", \"RC\", \"RD\", \"RE\", \"RF\", \"RG\", \"RH\", \"RI\", \"RJ\", \"RK\", \"RL\"],\n",
    "    \"reg6bis/0178\": [\"RM\", \"RN\", \"RO\", \"RP\", \"RQ\", \"RR\", \"RS\", \"RT\", \"RU\", \"RV\", \"RW\", \"RX\", \"RY\", \"RZ\", \"SA\", \"SB\", \"SC\", \"SD\", \"SE\"],\n",
    "    \"reg6bis/0179\": [\"SF\", \"SG\", \"SH\", \"SI\", \"SJ\", \"SK\", \"SL\", \"SM\"],\n",
    "    \"reg6bis/0180\": [\"SN\", \"SO\",\"SP\", \"SQ\", \"SR\", \"SS\", \"ST\", \"SU\"],\n",
    "    \"reg6bis/0181\": [\"SV\", \"SW\", \"SX\", \"SY\", \"SZ\", \"TA\", \"TB\", \"TC\", \"TD\", \"TE\", \"TF\"],\n",
    "    \"reg6bis/0182\": [\"TG\", \"TH\", \"TI\", \"TJ\", \"TK\", \"TL\", \"TM\", \"TN\", \"TO\", \"TP\", \"TQ\", \"TR\", \"TS\", \"TT\", \"TU\", \"TV\", \"TW\", \"TX\", \"TY\", \"TZ\", \"UA\"],\n",
    "    \"reg6bis/0183\": [\"UB\", \"UC\", \"UD\", \"UE\", \"UF\", \"UG\", \"UH\", \"UI\", \"UJ\", \"UK\", \"UL\", \"UM\"],\n",
    "    \"reg6bis/0184\": [\"UN\", \"UO\", \"UP\", \"UQ\", \"UR\", \"US\", \"UT\", \"UU\", \"UV\", \"UW\", \"UX\", \"UY\", \"UZ\", \"VA\", \"VB\", \"VC\"],\n",
    "    \"reg6bis/0185\": [\"VD\", \"VE\", \"VF\", \"VG\", \"VH\", \"VI\", \"VJ\", \"VK\", \"VL\", \"VM\", \"VN\", \"VO\", \"VP\", \"VQ\", \"VR\"],\n",
    "    \"reg6bis/0186\": [\"VS\", \"VT\", \"VU\", \"VV\", \"VW\", \"VX\", \"VY\", \"VZ\", \"XA\", \"XB\", \"XC\", \"XD\"]\n",
    "}\n",
    "\n",
    "def parcel_number_to_page(pn: str) -> str:\n",
    "    for img, pn_list in img_to_double_letter_pn.items():\n",
    "        if pn in pn_list:\n",
    "            return img\n",
    "    return None\n",
    "\n",
    "new_transc = new_transc.rename(columns=replace_d)\n",
    "\n",
    "new_transc['parcel_number'] = new_transc['parcel_number'].str.strip()\n",
    "# the new transcription leaves parcel_number empty in sub-parcel number following the sub-parcel-number of 1.0.\n",
    "new_transc['parcel_number'] = new_transc['parcel_number'].ffill()\n",
    "# to make them match to the geometries\n",
    "new_transc['parcel_number'] = new_transc['parcel_number'].replace('UJ', 'UI').replace('SJ', 'SI')\n",
    "\n",
    "new_transc['sub_parcel_number'] = new_transc['sub_parcel_number'].apply(lambda v: str(int(v)) if not np.isnan(v) else v)\n",
    "new_transc['ownership_types'] = [[]] * len(new_transc)\n",
    "new_transc['page'] = new_transc['parcel_number'].apply(parcel_number_to_page)\n",
    "new_transc['qualities'] = new_transc['qualities'].apply(lambda l: [v.strip().upper() for v in l.split(',')] if type(l) is str else l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "sommarioni_p = Path('../../1808_Sommarioni/')\n",
    "sommarioni_geo_fp = list(sommarioni_p.rglob('sommarioni_geometries_202*.geojson'))[0]\n",
    "sommarioni_txt_fp = list(sommarioni_p.rglob('sommarioni_text_data_with_pages_202*.json'))[0]\n",
    "df = pd.read_json(sommarioni_txt_fp)\n",
    "gdf = gpd.read_file(sommarioni_geo_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_number_to_geom_id = gdf.set_index('parcel_number')['geometry_id'].to_dict()\n",
    "# interesting mistake between the redaction of the map and the registry, a LG on the map was written where it should have been \"LC\" as written correctly in the registry\n",
    "# this is the only case where the geometry_id is not a bijection with the parcel numbers. \n",
    "lg_id = gdf[gdf['parcel_number'] == 'LG'].geometry_id.values[0]\n",
    "parcel_number_to_geom_id.update({'LC': lg_id})\n",
    "\n",
    "new_transc['geometry_id'] = new_transc['parcel_number'].apply(lambda v: parcel_number_to_geom_id[v] if v in parcel_number_to_geom_id else None)\n",
    "new_transc['geometry_id'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to find districts for each of those new transcriptions, using the centroid of the geometry of the corresponding parcel and the contemporary maps to find them.\n",
    "sgdf = gpd.read_file('../../contemporary_maps/2024_Sestiere_EPSG32633.geojson').to_crs('EPSG:4326')\n",
    "\n",
    "def sestiere_from_single_gps(gps, sgdf):\n",
    "    for i, row in sgdf.iterrows():\n",
    "        if row['geometry'].contains(gps):\n",
    "            return row['division_name']\n",
    "    return None\n",
    "\n",
    "new_transc_geoms = gdf[gdf['geometry_id'].isin(new_transc['geometry_id'].dropna())].dissolve(by='geometry_id')\n",
    "new_transc_geoms['coordinate'] = new_transc_geoms.centroid\n",
    "new_transc_geoms['sestiere'] = new_transc_geoms.apply(lambda row: sestiere_from_single_gps(row['coordinate'], sgdf), axis=1)\n",
    "new_transc_geoms['area'] = new_transc_geoms.area\n",
    "\n",
    "division_name_to_acronym = {\n",
    "    \"SAN POLO\": \"NSP\",\n",
    "    \"CANNAREGIO\":\"NCN\",\n",
    "\t\"SANTA CROCE\":\"NSC\",\n",
    "\t\"DORSODURO\":\"NDD\",\n",
    "\t\"SAN MARCO\":\"NSM\",\n",
    "\t\"CASTELLO\":\"NCS\",\n",
    "}\n",
    "new_transc_geoms['district_acronym'] = new_transc_geoms['sestiere'].apply(lambda v: division_name_to_acronym[v] if v in division_name_to_acronym else None)\n",
    "geom_id_to_district_acronym = new_transc_geoms.reset_index().set_index('geometry_id')['district_acronym'].to_dict()\n",
    "new_transc['district_acronym'] = new_transc['geometry_id'].apply(lambda v: geom_id_to_district_acronym[v] if v in geom_id_to_district_acronym else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to compute the area of each of the building of the new transcription\n",
    "new_transc_geoms = new_transc_geoms.to_crs('EPSG:32633')\n",
    "new_transc_geoms['area'] = new_transc_geoms.area\n",
    "geom_id_to_area = new_transc_geoms.reset_index().set_index('geometry_id')['area'].to_dict()\n",
    "\n",
    "new_transc['area'] = new_transc['geometry_id'].apply(lambda v: geom_id_to_area[v] if v in geom_id_to_area else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the unique id to the new transcriptions, to make the uuid already generated the same, we just add the new transcription to the range\n",
    "max_unique_id = int(df.unique_id.max())\n",
    "new_transc['unique_id'] = range(max_unique_id, max_unique_id + len(new_transc))\n",
    "df['unique_id'] = df['unique_id'].astype(int)\n",
    "df['new_transcription'] = False\n",
    "new_transc['new_transcription'] = True\n",
    "df = pd.concat([df, new_transc], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('3_Sommarioni_with_new_transcriptions_20250226.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
